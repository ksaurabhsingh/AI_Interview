+-------------------------------------+
|           Start                     |
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 1: Preprocess Text            |
|  - Tokenize and clean text          |
|  - Remove custom stopwords          |
|  - Apply Lemmatization/Stemming     |  <-- New step
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 2: Generate N-grams (Uni, Bi, Tri) |
|  - Extract unigrams, bigrams, and trigrams |
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 3: Generate Contextual Embeddings |
|  - Use a pre-trained model (e.g., SentenceTransformers) |
|  - Embed n-grams into vector space |
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 4: Build Graph               |
|  - Create nodes for each n-gram    |
|  - Add edges based on co-occurrence and semantic similarity |
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 5: Apply TextRank            |
|  - Rank the nodes based on their importance using PageRank |
+-------------------------------------+
             |
             v
+-------------------------------------+
|  Step 6: Extract Top Keywords      |
|  - Select the top n keywords based on TextRank scores |
+-------------------------------------+
             |
             v
+-------------------------------------+
|           End                       |
+-------------------------------------+
